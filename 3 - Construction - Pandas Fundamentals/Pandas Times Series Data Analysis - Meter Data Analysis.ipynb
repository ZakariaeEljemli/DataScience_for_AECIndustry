{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pandas Times Series Data Analysis - Meter Data Analysis.ipynb","provenance":[],"collapsed_sections":["k7ZifF2lZu3q"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PSiTpGicE4Q6"},"source":["# Time Series Data Analysis using Pandas\n","\n","- Created by Clayton Miller - clayton@nus.edu.sg - miller.clayton@gmail.com\n","\n","This notebook is an introduction to several key time-series functions available in the Pandas library. \n","\n","Several portions of the function explanations are from: https://www.dataquest.io/blog/tutorial-time-series-analysis-with-pandas/"]},{"cell_type":"markdown","metadata":{"id":"KPBxYrcTU2ud","colab_type":"text"},"source":["## The Building Data Genome Project\n","\n","For this set of videos, we will be using the Building Data Genome Project:\n","\n","https://github.com/buds-lab/the-building-data-genome-project\n","\n","![alt text](https://raw.githubusercontent.com/buds-lab/the-building-data-genome-project/master/figures/buildingdatagenome1.png)\n","\n","This project is a set of 500+ time-series meter data from buildings -- check out the website which includes an overview of the data set, sources, and publications that use the data set. \n","\n","In this notebook, we will use some of the buildings from that data set to understand why Pandas was designed for time-series data from IoT networks\n","\n","First, we will load the libraries and mount the drives as usual"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Bp1GGXTME4Q8","colab":{}},"source":["import pandas as pd\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NwHDVlyLF0iL","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DAytEebcIchs","colab":{}},"source":["os.chdir(\"/content/gdrive/My Drive/EDX Data Science for Construction, Architecture and Engineering/3 - Construction - Pandas Fundamentals/meter_data/\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8l3kV8FXvLdD","colab_type":"text"},"source":["Let's begin this demonstration of time-series data analysis by loading the data from a single building from the `Building Data Genome Project` -- this building has the name `Abilgail`\n","\n","You can notice that this time there is a column in the data set called `timestamp`. If we load the DataFrame the usual way then this column will just be a string data type:\n"]},{"cell_type":"code","metadata":{"id":"YGFVn1OQVrBW","colab_type":"code","colab":{}},"source":["abigail = pd.read_csv('Office_Abigail.csv', index_col = \"timestamp\") "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MWOtCOUDVw1n","colab_type":"code","colab":{}},"source":["abigail.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0fMWzDuV0dL","colab_type":"code","colab":{}},"source":["abigail.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"In7OaL1IV4YC","colab_type":"code","colab":{}},"source":["abigail.index[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OQHXIb-0V7fC","colab_type":"text"},"source":["## Setting the `timestamp` index to a *datetime* object \n","\n","Pandas has several very useful functions that we will cover in this notebook, but first we need to indicate to Pandas that the index is not just a regular string -- it has information related to date and time attributes including whether the day is **Monday** or **Tuesday** or whether that is a weekday or weekend. \n","\n","We can tell the `.read_csv()` function that it should **parse** the index and try to convert it into a *datetime* object. Let's see what happens when we do that."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fBMdZz5ME4RD","colab":{}},"source":["abigail = pd.read_csv('Office_Abigail.csv', index_col = \"timestamp\", parse_dates=True) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"j-xu-TF4E4RF","colab":{}},"source":["abigail.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CpwOtn5xE4RJ","colab":{}},"source":["abigail.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"35V_vrh7Wjjl","colab_type":"code","colab":{}},"source":["abigail.index[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pz6S7C9-VWF8","colab_type":"text"},"source":["## `Timestamp` object attributes\n","\n","You will notice that the index is not what's known as a `DateTimeIndex` and each of the index items is a `Timestamp` object. This allows us to as the object things like what day of the week it is and other attributes. \n","\n","More info here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html\n"]},{"cell_type":"code","metadata":{"id":"gOsch-m6X5Gy","colab_type":"code","colab":{}},"source":["abigail.index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PmT8epjfW411","colab_type":"code","colab":{}},"source":["abigail.index[0].month"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xXbV2ey-W47C","colab_type":"code","colab":{}},"source":["abigail.index[0].dayofweek"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-61PeTjjW4_5","colab_type":"code","colab":{}},"source":["abigail.index[0].week"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6HXGyxIsW5Cv","colab_type":"code","colab":{}},"source":["abigail.index[0].is_leap_year"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0y4ORih5W49q","colab_type":"code","colab":{}},"source":["abigail.index[0].hour"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5uxfwzGVW44l","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wTLXl4DzFF-B"},"source":["# Plotting simple line charts of time-series data\n","\n","The first thing we can do with the data is to explore it as a line chart. This gives us an understanding of the shape, frequency and potential for outliers. Data exploration is the first step in the analysis process."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"i_Tl9exfE4RN","colab":{}},"source":["abigail.plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VvbLOofXE4RQ","colab":{}},"source":["abigail.plot(marker='.', alpha=0.5, linestyle='None', figsize=(15, 5))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VNodfPKHE4RT"},"source":["# Resample the data to other frequencies\n","\n","\"It is often useful to resample our time series data to a lower or higher frequency. Resampling to a lower frequency (downsampling) usually involves an aggregation operation — for example, computing monthly sales totals from daily data. The daily OPSD data we’re working with in this tutorial was downsampled from the original hourly time series. Resampling to a higher frequency (upsampling) is less common and often involves interpolation or other data filling method — for example, interpolating hourly weather data to 10 minute intervals for input to a scientific model.\n","\n","We will focus here on downsampling, exploring how it can help us analyze our OPSD data on various time scales. We use the DataFrame’s `resample()` method, which splits the DatetimeIndex into time bins and groups the data by time bin. The `resample()` method returns a Resampler object, similar to a pandas GroupBy object. We can then apply an aggregation method such as `mean()`, `median()`, `sum()`, etc., to the data group for each time bin.\" -- from: https://www.dataquest.io/blog/tutorial-time-series-analysis-with-pandas/\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4UcB5v-_E4RT","colab":{}},"source":["abigail.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N7Aik20MHaJ3","colab_type":"text"},"source":["We can first resample to daily data by using the `D` as an attribute in the `.resample()` function to indicate that we want *daily* data aggregation. We use the `.mean()` function to indicate that we want the function to take the average across each day's hourly readings to produce the aggregated value for the day"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MVuNMmzEE4RW","colab":{}},"source":["abigail_daily = abigail.resample(\"D\").mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Lg1DY1l3E4RY","colab":{}},"source":["abigail_daily.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LqtpGVwrE4Rb","colab":{}},"source":["abigail_daily.plot(figsize=(10,5))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pUUTzrcdH3U8","colab_type":"text"},"source":["We can do the same to create *monthly* data and other aggregations"]},{"cell_type":"code","metadata":{"id":"kaj-LQ-0HYm1","colab_type":"code","colab":{}},"source":["abigail_daily.resample(\"M\").mean().plot(figsize=(10,5))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k7ZifF2lZu3q","colab_type":"text"},"source":["## Frequencies \n","\n","The Pandas Library has dozens of **frequencies** that can be used to resample data -- the detailed list is here: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"x6WVADIlE4Re"},"source":["# Truncating Time-Series Data\n","\n","The truncate function allows us to slice the data into smaller dataframes according to a time range\n","\n","Pandas DataFrame.truncate() function is used to truncate a Series or DataFrame before and after some index value. This is a useful shorthand for boolean indexing based on index values above or below certain thresholds.\n","\n","https://www.geeksforgeeks.org/python-pandas-dataframe-truncate/"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"akqKz321E4Re","colab":{}},"source":["abigail_daily.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MgIo_RMsE4Ri","colab":{}},"source":["abigail_daily_june = abigail_daily.truncate(before = '2015-06-01', after='2015-07-01')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3u8MGcViE4Rj","colab":{}},"source":["abigail_daily_june.plot(figsize=(10,5))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BU7-L7JEhAmv","colab_type":"text"},"source":["# Trends Analysis and Rolling Windows\n","\n","\"Time series data often exhibit some slow, gradual variability in addition to higher frequency variability such as seasonality and noise. An easy way to visualize these trends is with rolling means at different time scales.\n","\n","A rolling mean tends to smooth a time series by averaging out variations at frequencies much higher than the window size and averaging out any seasonality on a time scale equal to the window size. This allows lower-frequency variations in the data to be explored. Since our electricity consumption time series has weekly and yearly seasonality, let’s look at rolling means on those two time scales.\" - https://www.dataquest.io/blog/tutorial-time-series-analysis-with-pandas/"]},{"cell_type":"code","metadata":{"id":"qyysi5kNhJau","colab_type":"code","colab":{}},"source":["abigail.rolling(window=500, center=True, min_periods=500).mean().plot()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F4FJU_ulh2NK","colab_type":"text"},"source":["# Analysis of a large number of buildings at once\n","\n","Let's look at a larger group of buildings to understand how these functions can enhanced the analysis of a large number of buildings"]},{"cell_type":"code","metadata":{"id":"BfLlwvNXhPsm","colab_type":"code","colab":{}},"source":["os.listdir()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lwj0l38mjz4b","colab_type":"text"},"source":["Using that list, let's take all the buildings that have a time range of 2015"]},{"cell_type":"code","metadata":{"id":"LORBrHESiFiq","colab_type":"code","colab":{}},"source":["list_of_buildings = ['UnivClass_Andy.csv',\n","'Office_Abbey.csv',\n","'Office_Alannah.csv',\n","'PrimClass_Angel.csv',\n","'Office_Penny.csv',\n","'Office_Pam.csv',\n","'UnivClass_Craig.csv',\n","'UnivLab_Allison.csv',\n","'Office_Amelia.csv',\n","'Office_Aubrey.csv',\n","'Office_Cecelia.csv',\n","'UnivClass_Conor.csv',\n","'Office_Autumn.csv',\n","'Office_Abigail.csv',\n","'Office_Amelie.csv',\n","'UnivClass_Alfredo.csv',\n","'Office_Phebian.csv',\n","'UnivLab_Adrian.csv',\n","'UnivDorm_Curtis.csv',\n","'UnivLab_Angie.csv',\n","'UnivClass_Amya.csv',\n","'UnivDorm_Cian.csv',\n","'UnivClass_Ciara.csv',\n","'UnivLab_Audra.csv',\n","'UnivLab_Ciel.csv',\n","'UnivLab_Cesar.csv']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TdDOCcQiiJ_p","colab_type":"code","colab":{}},"source":["all_data_list = []\n","for buildingname in list_of_buildings:\n","  df = pd.read_csv(buildingname, index_col = \"timestamp\", parse_dates=True) \n","  df = df.resample(\"H\").mean()\n","  all_data_list.append(df)\n","all_data = pd.concat(all_data_list, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mg8aE21viicv","colab_type":"code","colab":{}},"source":["all_data.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CE69W8Vyi3n7","colab_type":"code","colab":{}},"source":["all_data.plot(figsize=(20,30), subplots=True);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gsbxMv6KjcRD","colab_type":"code","colab":{}},"source":["all_data.resample(\"D\").mean().plot(figsize=(20,30), subplots=True);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sEXrPlzPj-l0","colab_type":"code","colab":{}},"source":["all_data.resample(\"D\").mean().truncate(after='2015-06-01').plot(figsize=(20,30), subplots=True);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mQx4o7XxlAgi","colab_type":"text"},"source":["## Filter columns by query\n","\n","Let's just look at the *office* buildings by filtering the columns based on name"]},{"cell_type":"code","metadata":{"id":"BYKbhXdHk7qn","colab_type":"code","colab":{}},"source":["all_data.columns[all_data.columns.str.contains(\"Office\")]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Rimo_STlO5S","colab_type":"code","colab":{}},"source":["all_data[all_data.columns[all_data.columns.str.contains(\"Office\")]].info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4IsHdVw-laM6","colab_type":"code","colab":{}},"source":["all_data[all_data.columns[all_data.columns.str.contains(\"Office\")]].plot(figsize=(15,15), subplots=True);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"661rYXhllkNW","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}